{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"anaconda-cloud":{}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GroupBy and Aggregate Functions\n\nLet's learn how to use GroupBy and Aggregate methods on a DataFrame. GroupBy allows you to group rows together based off some column value, for example, you could group together sales data by the day the sale occured, or group repeast customer data based off the name of the customer. Once you've performed the GroupBy operation you can use an aggregate function off that data. An aggregate function aggregates multiple rows of data into a single output, such as taking the sum of inputs, or counting the number of inputs.\n\nLet's see some examples on an example dataset!","metadata":{}},{"cell_type":"code","source":"pip install pyspark","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:17:18.478404Z","iopub.execute_input":"2022-06-28T16:17:18.478903Z","iopub.status.idle":"2022-06-28T16:17:18.542806Z","shell.execute_reply.started":"2022-06-28T16:17:18.478804Z","shell.execute_reply":"2022-06-28T16:17:18.541635Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# May take a little while on a local computer\nspark = SparkSession.builder.appName(\"groupbyagg\").getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:17:19.579227Z","iopub.execute_input":"2022-06-28T16:17:19.579656Z","iopub.status.idle":"2022-06-28T16:17:25.161053Z","shell.execute_reply.started":"2022-06-28T16:17:19.579620Z","shell.execute_reply":"2022-06-28T16:17:25.159616Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Read in the customer sales data","metadata":{}},{"cell_type":"code","source":"df = spark.read.csv('../input/salesinfo/sales_info.csv',inferSchema=True,header=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:18:26.768697Z","iopub.execute_input":"2022-06-28T16:18:26.769413Z","iopub.status.idle":"2022-06-28T16:18:33.196083Z","shell.execute_reply.started":"2022-06-28T16:18:26.769359Z","shell.execute_reply":"2022-06-28T16:18:33.194811Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.printSchema()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:18:33.198052Z","iopub.execute_input":"2022-06-28T16:18:33.198527Z","iopub.status.idle":"2022-06-28T16:18:33.215442Z","shell.execute_reply.started":"2022-06-28T16:18:33.198484Z","shell.execute_reply":"2022-06-28T16:18:33.214224Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:18:35.474019Z","iopub.execute_input":"2022-06-28T16:18:35.474678Z","iopub.status.idle":"2022-06-28T16:18:35.830696Z","shell.execute_reply.started":"2022-06-28T16:18:35.474642Z","shell.execute_reply":"2022-06-28T16:18:35.829501Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Let's group together by company!","metadata":{}},{"cell_type":"code","source":"df.groupBy(\"Company\")","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:18:41.045205Z","iopub.execute_input":"2022-06-28T16:18:41.045608Z","iopub.status.idle":"2022-06-28T16:18:41.076289Z","shell.execute_reply.started":"2022-06-28T16:18:41.045576Z","shell.execute_reply":"2022-06-28T16:18:41.075328Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"This returns a GroupedData object, off of which you can all various methods","metadata":{}},{"cell_type":"code","source":"# Mean\ndf.groupBy(\"Company\").mean().show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:18:52.417494Z","iopub.execute_input":"2022-06-28T16:18:52.418188Z","iopub.status.idle":"2022-06-28T16:18:53.677077Z","shell.execute_reply.started":"2022-06-28T16:18:52.418151Z","shell.execute_reply":"2022-06-28T16:18:53.675386Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Count\ndf.groupBy(\"Company\").count().show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:18:57.521139Z","iopub.execute_input":"2022-06-28T16:18:57.521622Z","iopub.status.idle":"2022-06-28T16:18:57.962743Z","shell.execute_reply.started":"2022-06-28T16:18:57.521580Z","shell.execute_reply":"2022-06-28T16:18:57.961484Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Max\ndf.groupBy(\"Company\").max().show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:19:00.237084Z","iopub.execute_input":"2022-06-28T16:19:00.237525Z","iopub.status.idle":"2022-06-28T16:19:00.652660Z","shell.execute_reply.started":"2022-06-28T16:19:00.237490Z","shell.execute_reply":"2022-06-28T16:19:00.651360Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Min\ndf.groupBy(\"Company\").min().show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:19:05.754191Z","iopub.execute_input":"2022-06-28T16:19:05.754653Z","iopub.status.idle":"2022-06-28T16:19:06.151873Z","shell.execute_reply.started":"2022-06-28T16:19:05.754616Z","shell.execute_reply":"2022-06-28T16:19:06.150534Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Sum\ndf.groupBy(\"Company\").sum().show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:19:10.860350Z","iopub.execute_input":"2022-06-28T16:19:10.860839Z","iopub.status.idle":"2022-06-28T16:19:11.208042Z","shell.execute_reply.started":"2022-06-28T16:19:10.860799Z","shell.execute_reply":"2022-06-28T16:19:11.207093Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Check out this link for more info on other methods:\nhttp://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark-sql-module\n\nNot all methods need a groupby call, instead you can just call the generalized .agg() method, that will call the aggregate across all rows in the dataframe column specified. It can take in arguments as a single column, or create multiple aggregate calls all at once using dictionary notation.\n\nFor example:","metadata":{}},{"cell_type":"code","source":"# Max sales across everything\ndf.agg({'Sales':'max'}).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:19:45.960548Z","iopub.execute_input":"2022-06-28T16:19:45.961183Z","iopub.status.idle":"2022-06-28T16:19:46.504663Z","shell.execute_reply.started":"2022-06-28T16:19:45.961133Z","shell.execute_reply":"2022-06-28T16:19:46.503479Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Could have done this on the group by object as well:","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grouped = df.groupBy(\"Company\")","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:20:19.548714Z","iopub.execute_input":"2022-06-28T16:20:19.549198Z","iopub.status.idle":"2022-06-28T16:20:19.563387Z","shell.execute_reply.started":"2022-06-28T16:20:19.549157Z","shell.execute_reply":"2022-06-28T16:20:19.561956Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"grouped.agg({\"Sales\":'max'}).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:20:24.839136Z","iopub.execute_input":"2022-06-28T16:20:24.839565Z","iopub.status.idle":"2022-06-28T16:20:25.087056Z","shell.execute_reply.started":"2022-06-28T16:20:24.839530Z","shell.execute_reply":"2022-06-28T16:20:25.086188Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Functions\nThere are a variety of functions you can import from pyspark.sql.functions. Check out the documentation for the full list available:\nhttp://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import countDistinct, avg,stddev","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:20:53.448217Z","iopub.execute_input":"2022-06-28T16:20:53.448637Z","iopub.status.idle":"2022-06-28T16:20:53.454059Z","shell.execute_reply.started":"2022-06-28T16:20:53.448604Z","shell.execute_reply":"2022-06-28T16:20:53.452716Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"df.select(countDistinct(\"Sales\")).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:20:55.940805Z","iopub.execute_input":"2022-06-28T16:20:55.941237Z","iopub.status.idle":"2022-06-28T16:20:56.347488Z","shell.execute_reply.started":"2022-06-28T16:20:55.941202Z","shell.execute_reply":"2022-06-28T16:20:56.346279Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Often you will want to change the name, use the .alias() method for this:","metadata":{}},{"cell_type":"code","source":"df.select(countDistinct(\"Sales\").alias(\"Distinct Sales\")).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:21:03.084342Z","iopub.execute_input":"2022-06-28T16:21:03.084789Z","iopub.status.idle":"2022-06-28T16:21:03.337820Z","shell.execute_reply.started":"2022-06-28T16:21:03.084746Z","shell.execute_reply":"2022-06-28T16:21:03.336560Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.select(avg('Sales')).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:21:32.649700Z","iopub.execute_input":"2022-06-28T16:21:32.650116Z","iopub.status.idle":"2022-06-28T16:21:32.983040Z","shell.execute_reply.started":"2022-06-28T16:21:32.650080Z","shell.execute_reply":"2022-06-28T16:21:32.981631Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df.select(stddev(\"Sales\")).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:22:13.151118Z","iopub.execute_input":"2022-06-28T16:22:13.151708Z","iopub.status.idle":"2022-06-28T16:22:13.400121Z","shell.execute_reply.started":"2022-06-28T16:22:13.151667Z","shell.execute_reply":"2022-06-28T16:22:13.398779Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"That is a lot of precision for digits! Let's use the format_number to fix that!","metadata":{}},{"cell_type":"code","source":"from pyspark.sql.functions import format_number","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:22:17.758502Z","iopub.execute_input":"2022-06-28T16:22:17.758917Z","iopub.status.idle":"2022-06-28T16:22:17.763921Z","shell.execute_reply.started":"2022-06-28T16:22:17.758885Z","shell.execute_reply":"2022-06-28T16:22:17.763046Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"sales_std = df.select(stddev(\"Sales\").alias('std'))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T16:22:20.862742Z","iopub.execute_input":"2022-06-28T16:22:20.864066Z","iopub.status.idle":"2022-06-28T16:22:20.884433Z","shell.execute_reply.started":"2022-06-28T16:22:20.864007Z","shell.execute_reply":"2022-06-28T16:22:20.883107Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"sales_std.show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:24:08.831434Z","iopub.execute_input":"2022-06-28T16:24:08.832051Z","iopub.status.idle":"2022-06-28T16:24:09.018620Z","shell.execute_reply.started":"2022-06-28T16:24:08.832006Z","shell.execute_reply":"2022-06-28T16:24:09.017315Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# format_number(\"col_name\",decimal places)\nsales_std.select(format_number('std',2)).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:24:14.496030Z","iopub.execute_input":"2022-06-28T16:24:14.496932Z","iopub.status.idle":"2022-06-28T16:24:14.718266Z","shell.execute_reply.started":"2022-06-28T16:24:14.496893Z","shell.execute_reply":"2022-06-28T16:24:14.717020Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Order By\n\nYou can easily sort with the orderBy method:","metadata":{}},{"cell_type":"code","source":"# OrderBy\n# Ascending\ndf.orderBy(\"Sales\").show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:24:20.779230Z","iopub.execute_input":"2022-06-28T16:24:20.779674Z","iopub.status.idle":"2022-06-28T16:24:20.994991Z","shell.execute_reply.started":"2022-06-28T16:24:20.779640Z","shell.execute_reply":"2022-06-28T16:24:20.993554Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Descending call off the column itself.\ndf.orderBy(df[\"Sales\"].desc()).show()","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-28T16:25:09.169458Z","iopub.execute_input":"2022-06-28T16:25:09.169854Z","iopub.status.idle":"2022-06-28T16:25:09.364744Z","shell.execute_reply.started":"2022-06-28T16:25:09.169824Z","shell.execute_reply":"2022-06-28T16:25:09.363500Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Most basic functions you would expect to be available are, so make sure to check out the documentation!","metadata":{}}]}